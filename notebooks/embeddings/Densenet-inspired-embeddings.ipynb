{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf896af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5781dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import densenet\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40800c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.11s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.60s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.12s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "sys.path.append('../dataset/')\n",
    "import coco_data_prep\n",
    "import coco_api_helper\n",
    "import config_dataset\n",
    "\n",
    "sys.path.append('../models/')\n",
    "import densenet_inspired as di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd5be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf74beb",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a23d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_np_data_dir = '../data/numpy_imgs/val_subset/'\n",
    "val_jpg_data_dir = '../data/raw/val/val2014/'\n",
    "val_annot_filepath = '../data/raw/train/annotations/instances_val2014.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "145000e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params= dict(\n",
    "    lr=0.001,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-05,\n",
    "    weight_decay=0.01,\n",
    "    amsgrad=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a7aef",
   "metadata": {},
   "source": [
    "### Load Checkpointed Model & Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64304968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/envs/cs7643-raml/lib/python3.8/site-packages/torch/nn/modules/lazy.py:175: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DensenetInspired(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (conv3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin1): LazyLinear(in_features=0, out_features=1024, bias=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = di.DensenetInspired()\n",
    "optimizer = torch.optim.Adam(model.parameters(), **optim_params)\n",
    "\n",
    "checkpoint = torch.load('./checkpoints/densenet_inspired_epoch_11.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bcf00bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (10): Flatten(start_dim=1, end_dim=-1)\n",
       "  (11): LazyLinear(in_features=0, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slice_model(original_model, from_layer=None, to_layer=None):\n",
    "    return nn.Sequential(*list(original_model.children())[from_layer:to_layer])\n",
    "\n",
    "model_conv_features = slice_model(model, to_layer=-1).to('cpu')\n",
    "model_conv_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89478df",
   "metadata": {},
   "source": [
    "### Make Embeddings for all Val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9187d516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=6.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 40504/40504 [00:27<00:00, 1472.11it/s]\n"
     ]
    }
   ],
   "source": [
    "all_val_ds = coco_data_prep.COCODataset('val',\n",
    "                                        val_np_data_dir, \n",
    "                                        val_annot_filepath,\n",
    "                                        coco_data_prep.COCOAnnotationTransform(),\n",
    "                                        device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9b5c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_dl = coco_data_prep.get_dataloader(all_val_ds, \n",
    "                                         batch_size=256, \n",
    "                                         device='cpu',\n",
    "                                         loader_params={'num_workers': 0,\n",
    "                                                        'shuffle': False,\n",
    "                                                        'collate_fn': lambda x : x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3595f6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1fc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:33,  1.93s/it]"
     ]
    }
   ],
   "source": [
    "features_list = []\n",
    "\n",
    "# Use GPUs to speed up the inference, this should take around 10 minutes\n",
    "model_conv_features.to('cpu')\n",
    "\n",
    "for i, batch in tqdm(enumerate(all_val_dl)):    \n",
    "    image_batch, _ = [x[0] for x in batch], [x[1] for x in batch]\n",
    "    image_batch = torch.stack(image_batch).to('cpu')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features_batch = model_conv_features(image_batch)\n",
    "        \n",
    "    features_list.append(features_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f242c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7643-raml",
   "language": "python",
   "name": "cs7643-raml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
